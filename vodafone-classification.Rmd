---
title: "vodafone-classification"
author: "ahmed-akram"
date: "May 23, 2016"
output: html_document
---

```{r, message=FALSE, comment=NA}

library(plyr)
library(e1071)
library(rpart)
library(randomForest)
library(neuralnet)
library(dplyr)
library(ipred)

set.seed(10)


# model_train <- read.csv("data/train.csv")
# model_test <- read.csv("data/test.csv")
```

```{r adding the roaming counter to datasets}
daily_roaming_counter <- daily %>% group_by(CONTRACT_KEY) %>% summarise(roaming_counter = sum(as.numeric(ROAMING_FLAG)))

hash<-new.env()
for(i in 1:(daily_roaming_counter %>% nrow)) {
	hash[[as.character(daily_roaming_counter[i,]$CONTRACT_KEY)]] <- daily_roaming_counter[i,]$roaming_counter
}

add_roaming_counter <- function(data) {
	data$ROAMING_COUNTER <- data %>% apply(1, function(row) {
		if(is.null(hash[[as.character(row[['CONTRACT_KEY']])]])) {
			return(NA)
		}
		return(hash[[as.character(row[['CONTRACT_KEY']])]])
	})
	data
}

model_train <- add_roaming_counter(model_train)
model_test <- add_roaming_counter(model_test)
```

```{r adding the diff features}
add_differences <- function(data) {
	subtrain <- data
	subtrain$diff_one2 <- subtrain %>% apply(1, function(x) {
		(x[['MONTH3_USAGE']] / mean(c(x[['MONTH1_USAGE']], x[['MONTH2_USAGE']]))) * 100
	})
	
	subtrain$diff_two2 <- subtrain %>% apply(1, function(x) {
		(x[['MONTH4_USAGE']] / mean(c(x[['MONTH2_USAGE']], x[['MONTH3_USAGE']]))) * 100
	})
	
	subtrain$diff_three2 <- subtrain %>% apply(1, function(x) {
		(x[['MONTH5_USAGE']] / mean(c(x[['MONTH3_USAGE']], x[['MONTH4_USAGE']]))) * 100
	})

	subtrain
}

add_differences2 <- function(data) {
	subtrain <- data
	subtrain$diff_one <- subtrain %>% apply(1, function(x) {
		if(x[['MONTH3_USAGE']] > mean(c(x[['MONTH1_USAGE']], x[['MONTH2_USAGE']])) + 500) {
			return(1)
		}
		return(0)
	})
	
	subtrain$diff_two <- subtrain %>% apply(1, function(x) {
		if(x[['MONTH4_USAGE']] > mean(c(x[['MONTH2_USAGE']], x[['MONTH3_USAGE']])) + 500) {
			return(1)
		}
		return(0)
	})
	
	subtrain$diff_three <- subtrain %>% apply(1, function(x) {
		if(x[['MONTH5_USAGE']] > mean(c(x[['MONTH3_USAGE']], x[['MONTH4_USAGE']])) + 500) {
			return(1)
		}
		return(0)
	})
	subtrain
}

model_train <- add_differences(model_train)
model_train <- add_differences2(model_train)

model_test <- add_differences(model_test)
model_test <- add_differences2(model_test)
```

```{r cross validation function}
cross_validate <- function(data, model, class, folds, ntree = NULL, print=FALSE, type=NULL, frm=NULL) {
    # folds
    k = folds
    
    # give each row an id from 1:k representing which fold it's in
    data$id <- sample(1:k, nrow(data), replace = TRUE)
    list <- 1:k
    
    data[[class]] <- factor(data[[class]])
    
    progress.bar <- create_progress_bar("text")
    progress.bar$init(k)
    
    accuracies = c()
    precisions = c()
    recalls = c()
    f_scores = c()
    
    for (i in 1:k){
        # get all rows with id != i to be in training set and those with id == i will be testing set
        trainingset <- data %>% subset(id %in% list[-i])
        testset <- data %>% subset(id %in% c(i))
        # building the formula
        if(is.null(frm)) {
        	frm <- paste(class, ".", sep=" ~ ")
        }
        print(frm)
        # building the fitting model
        if(is.null(ntree)) {
            fit <- frm %>% formula %>% model(data=data)
        }else if(!is.null(type)) {
            fit <- frm %>% formula %>% model(data=data, type=type)
        }else{
            fit <- frm %>% formula %>% model(data=data, ntree = ntree)
        }
        
        # get the index of the class in the list of feature names
        index <- which(data %>% names == class)
        
        # predict on the test set without the desired class column
        pred <- predict(fit, testset[,-index])
        
        confusion_matrix <- table(pred, testset[[class]])
        #rownames(confusion_matrix) <- c("Predicted No", "Predicted Yes")
        #colnames(confusion_matrix) <- c("Actual No", "Actual Yes")
        
        if(print) {
            print(confusion_matrix)
        }
        
        TN <- confusion_matrix[1,1]
        TP <- confusion_matrix[2,2]
        FP <- confusion_matrix[2,1]
        FN <- confusion_matrix[1,2]
        
        accuracy <- (TP + TN) / (testset %>% nrow)
        precision <- (TP) / (FP + TP)
        recall <- (TP) / (TP + FN)
        f_score <- 2 * (recall * precision) / (recall + precision)
        
        accuracies <- accuracies %>% append(accuracy)
        precisions <- precisions %>% append(precision)
        recalls <- recalls %>% append(recall)
        f_scores <- f_scores %>% append(f_score)
        
        progress.bar$step()
    }
    
    return (as.data.frame(list("Accuracy" = accuracies, 
                               "Precision" = precisions,
                               "Recall" = recalls,
                               "F_Score" = f_scores)))
}
```

```{r divide into train and test for local validation}
nr <- NROW(model_train)
ind <- sample(nr, 0.8 * nr, replace = FALSE)
train <- model_train[ind,]
test <- model_train[-ind,]
```

```{r Best score with naive bayes}
fit <- naiveBayes(as.factor(TARGET) ~ diff_one + diff_two + diff_three + diff_one2 + diff_two2 + diff_three2 + TOTAL_USAGE, data = train)
pred <- predict(fit, newdata = test[, -12])
confusion_matrix <- table(pred, test$TARGET)
confusion_matrix

TN <- confusion_matrix[1,1]
TP <- confusion_matrix[2,2]
FP <- confusion_matrix[2,1]
FN <- confusion_matrix[1,2]
accuracy <- (TP + TN) / (test %>% nrow)
accuracy
```

```{r submit}
submit <- function(number, fit, data) {
	
	ind <- which(data %>% names == "TARGET")
	pred <- predict(fit, newdata = data[, -ind])

	data <- data %>% dplyr::select(CONTRACT_KEY)
	data$PREDICTED_TARGET = pred
	
	file <- paste("submissions/submission-", number, ".csv", sep="")
	write.csv(data, file, row.names = FALSE)
}
```
