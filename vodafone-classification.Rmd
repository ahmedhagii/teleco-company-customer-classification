---
title: "vodafone-classification"
author: "ahmed-akram"
date: "May 23, 2016"
output: html_document
---

```{r, message=FALSE, comment=NA}

library(plyr)
library(e1071)
library(rpart)
library(randomForest)
library(neuralnet)
library(dplyr)
library(ipred)
library(RWeka)

set.seed(10)


# model_train <- read.csv("data/train.csv")
# model_test <- read.csv("data/test.csv")
```

```{r adding the roaming counter to datasets}
daily_roaming_counter <- daily %>% group_by(CONTRACT_KEY) %>% summarise(roaming_counter = sum(as.numeric(ROAMING_FLAG)))

hash<-new.env()
for(i in 1:(daily_roaming_counter %>% nrow)) {
	hash[[as.character(daily_roaming_counter[i,]$CONTRACT_KEY)]] <- daily_roaming_counter[i,]$roaming_counter
}

add_roaming_counter <- function(data) {
	data$ROAMING_COUNTER <- data %>% apply(1, function(row) {
		if(is.null(hash[[as.character(row[['CONTRACT_KEY']])]])) {
			return(NA)
		}
		return(hash[[as.character(row[['CONTRACT_KEY']])]])
	})
	data
}

model_train <- add_roaming_counter(model_train)
model_test <- add_roaming_counter(model_test)
```

```{r adding the diff features}
add_differences <- function(data) {
	subtrain <- data
	subtrain$diff_one2 <- subtrain %>% apply(1, function(x) {
		(x[['MONTH3_USAGE']] / mean(c(x[['MONTH1_USAGE']], x[['MONTH2_USAGE']]))) * 100
	})
	
	subtrain$diff_two2 <- subtrain %>% apply(1, function(x) {
		(x[['MONTH4_USAGE']] / mean(c(x[['MONTH2_USAGE']], x[['MONTH3_USAGE']]))) * 100
	})
	
	subtrain$diff_three2 <- subtrain %>% apply(1, function(x) {
		(x[['MONTH5_USAGE']] / mean(c(x[['MONTH3_USAGE']], x[['MONTH4_USAGE']]))) * 100
	})

	subtrain
}

add_differences2 <- function(data) {
	subtrain <- data
	subtrain$diff_one <- subtrain %>% apply(1, function(x) {
		if(x[['MONTH3_USAGE']] > mean(c(x[['MONTH1_USAGE']], x[['MONTH2_USAGE']])) + 500) {
			return(1)
		}
		return(0)
	})
	
	subtrain$diff_two <- subtrain %>% apply(1, function(x) {
		if(x[['MONTH4_USAGE']] > mean(c(x[['MONTH2_USAGE']], x[['MONTH3_USAGE']])) + 500) {
			return(1)
		}
		return(0)
	})
	
	subtrain$diff_three <- subtrain %>% apply(1, function(x) {
		if(x[['MONTH5_USAGE']] > mean(c(x[['MONTH3_USAGE']], x[['MONTH4_USAGE']])) + 500) {
			return(1)
		}
		return(0)
	})
	subtrain
}

model_train <- add_differences(model_train)
model_train <- add_differences2(model_train)

model_test <- add_differences(model_test)
model_test <- add_differences2(model_test)
```

```{r cross validation function}
cross_validate <- function(data, model, class, folds, ntree = NULL, print=FALSE, type=NULL, frm=NULL) {
    # folds
    k = folds
    
    # give each row an id from 1:k representing which fold it's in
    data$id <- sample(1:k, nrow(data), replace = TRUE)
    list <- 1:k
    
    data[[class]] <- factor(data[[class]])
    
    progress.bar <- create_progress_bar("text")
    progress.bar$init(k)
    
    accuracies = c()
    precisions = c()
    recalls = c()
    f_scores = c()
    
    for (i in 1:k){
        # get all rows with id != i to be in training set and those with id == i will be testing set
        trainingset <- data %>% subset(id %in% list[-i])
        testset <- data %>% subset(id %in% c(i))
        # building the formula
        if(is.null(frm)) {
        	frm <- paste(class, ".", sep=" ~ ")
        }
        print(frm)
        # building the fitting model
        if(is.null(ntree)) {
            fit <- frm %>% formula %>% model(data=data)
        }else if(!is.null(type)) {
            fit <- frm %>% formula %>% model(data=data, type=type)
        }else{
            fit <- frm %>% formula %>% model(data=data, ntree = ntree)
        }
        
        # get the index of the class in the list of feature names
        index <- which(data %>% names == class)
        
        # predict on the test set without the desired class column
        pred <- predict(fit, testset[,-index])
        
        confusion_matrix <- table(pred, testset[[class]])
        #rownames(confusion_matrix) <- c("Predicted No", "Predicted Yes")
        #colnames(confusion_matrix) <- c("Actual No", "Actual Yes")
        
        if(print) {
            print(confusion_matrix)
        }
        
        TN <- confusion_matrix[1,1]
        TP <- confusion_matrix[2,2]
        FP <- confusion_matrix[2,1]
        FN <- confusion_matrix[1,2]
        
        accuracy <- (TP + TN) / (testset %>% nrow)
        precision <- (TP) / (FP + TP)
        recall <- (TP) / (TP + FN)
        f_score <- 2 * (recall * precision) / (recall + precision)
        
        accuracies <- accuracies %>% append(accuracy)
        precisions <- precisions %>% append(precision)
        recalls <- recalls %>% append(recall)
        f_scores <- f_scores %>% append(f_score)
        
        progress.bar$step()
    }
    
    return (as.data.frame(list("Accuracy" = accuracies, 
                               "Precision" = precisions,
                               "Recall" = recalls,
                               "F_Score" = f_scores)))
}
```

```{r}
model_train <- model_train %>% mutate(SUM_EXCEEDING = diff_one + diff_two + diff_three)
model_train <- model_train %>% mutate(MEAN_USAGE = TOTAL_USAGE / 5)

model_test <- model_test %>% mutate(SUM_EXCEEDING = diff_one + diff_two + diff_three) %>% mutate(MEAN_USAGE = TOTAL_USAGE / 5)
```

```{r}
model_train <- model_train %>% mutate(WEIGHTED_AVG = (5*MONTH5_USAGE + 4*MONTH4_USAGE + 3*MONTH3_USAGE + 2*MONTH2_USAGE + MONTH1_USAGE) / 15)

model_test <- model_test %>% mutate(WEIGHTED_AVG = (5*MONTH5_USAGE + 4*MONTH4_USAGE + 3*MONTH3_USAGE + 2*MONTH2_USAGE + MONTH1_USAGE) / 15)

model_test <- model_test %>% mutate(DIFF_BETWEEN_6th_AND_MEAN = WEIGHTED_AVG - MEAN_USAGE)

model_train <- model_train %>% mutate(DIFF_BETWEEN_6th_AND_MEAN = WEIGHTED_AVG - MEAN_USAGE)

model_train <- model_train %>% mutate(BIGGER_THAN = as.numeric(DIFF_BETWEEN_6th_AND_MEAN) > 105)

model_test <- model_test %>% mutate(BIGGER_THAN = as.numeric(DIFF_BETWEEN_6th_AND_MEAN) > 105)

model_train$BIGGER_THAN <- as.numeric(model_train$BIGGER_THAN)
model_test$BIGGER_THAN <- as.numeric(model_test$BIGGER_THAN)
```


```{r divide into train and test for local validation}
nr <- NROW(model_train)
ind <- sample(nr, 0.7 * nr, replace = FALSE)
train <- model_train[ind,]
test <- model_train[-ind,]

# nr <- NROW(model2)
# ind <- sample(nr, 0.7 * nr, replace = FALSE)
# train <- model2[ind,]
# test <- model2[-ind,]
```

```{r calculate function}
calculate <- function(fit) {
	pred <- predict(fit, newdata = test[, -12])
	confusion_matrix <- table(pred, test$TARGET)
	print(confusion_matrix)
	
	TN <- confusion_matrix[1,1]
	TP <- confusion_matrix[2,2]
	FP <- confusion_matrix[2,1]
	FN <- confusion_matrix[1,2]
	# accuracy <- (TP + TN) / (test %>% nrow)
	accuracy <- (TP + TN) / (TN + TP + FP + FN)
	print(accuracy)
	return(TP)
}
```

```{r Best score with naive bayes}
fit <- naiveBayes(as.factor(TARGET) ~ TOTAL_USAGE + sum + MEAN_USAGE, data = train)
calculate(fit)
```

```{r bagging}
fit <- bagging(as.factor(TARGET) ~ TOTAL_USAGE + sum + MEAN_USAGE, data = train)
calculate(fit)
```

```{r decision tree}
fit <- J48(as.factor(TARGET) ~ TOTAL_USAGE + SUM_EXCEEDING + MEAN_USAGE, data = train)
calculate(fit)
```

```{r random forest}
fit <- randomForest(as.factor(TARGET) ~ ., data = train, ntree=50)
calculate(fit)
```


```{r}
try_all <- function(model) {
# 	features <- c("TOTAL_USAGE", "BIGGER_THAN")
	features <- c("TOTAL_USAGE", "AVG_PER_SESSION", "SUM_EXCEEDING", "MEAN_USAGE", "WEIGHTED_AVG", "DIFF_BETWEEN_6th_AND_MEAN", "BIGGER_THAN")

	substrRight <- function(x, n){
		substr(x, nchar(x)-n+1, nchar(x))
	}
	
	max_score = 0
	best_form = ""
	
	train[["TARGET"]] <- factor(train[["TARGET"]])
	
	rec <- function(index, frm) {
		if(index > length(features)) {
			if(frm == "") {
				return(" .")
			}
			return(frm)
		}
		
		if(frm == "") {
			formula = paste(frm, features[index], sep=" ")
		}else {
			formula = paste(frm, features[index], sep=" + ")
		}
		
		used_formula <- formula
		frm2 <- paste("TARGET", used_formula, sep=" ~")
		print(frm2)
		
		if(model == 1) {
			fit <-  naiveBayes(as.formula(frm2), data = train)	
		}else if(model == 2) {
			fit <-  randomForest(as.formula(frm2), data = train, ntree=50)
		}else if(model == 3) {
			fit <-  bagging(as.formula(frm2), data = train)
		}else if(model == 4) {
			fit <-  J48(as.formula(frm2), data = train)
		}else if(model ==5) {
			fit <-  svm(as.formula(frm2), data = train, type="C-classification")			
		}
		res <- calculate(fit)
		if(as.numeric(res) > max_score) {
			best_form <<- frm2
			max_score <<- res
		}
		print("====================")
		rec(index + 1, formula)
		rec(index + 1, frm)
	}

	
	rec(1, "")
	print(paste("Best score achieved ", max_score, "with formula: ", best_form))
}
```


```{r try every possible formula attributes with the following algorithms}
sink("output/naivebayes.out", append=FALSE)
try_all(1)
sink()
sink()
print("Done [naiveBayes]")

sink("output/randomForest.out", append=FALSE)
try_all(2)
sink()
print("Done [randomForest]")

sink("output/bagging.out", append=FALSE)
try_all(3)
sink()
print("Done [bagging]")
# 
sink("output/J48.out", append=FALSE)
try_all(4)
sink()
print("Done [J48]")

sink("output/svm.out", append=FALSE)
try_all(5)
sink()
print("Done [svm]")

```


```{r submit}
submit <- function(number, fit, data) {
	
	ind <- which(data %>% names == "TARGET")
	pred <- predict(fit, newdata = data)
	print(pred %>% unique)
	
	# data <- data %>% dplyr::select(CONTRACT_KEY)
	data$PREDICTED_TARGET = pred
	data$PREDICTED_TARGET <- data %>% apply(1, function(row) {
		if(as.numeric(row[['DIFF_BETWEEN_6th_AND_MEAN']]) > 105) {
			return(1)
		}else {
			return(row[['PREDICTED_TARGET']])
		}
	})
	
	data <- data %>% select(CONTRACT_KEY, PREDICTED_TARGET)
	
	file <- paste("submissions/submission-", number, ".csv", sep="")
	write.csv(data, file, row.names = FALSE)
}
```


```{r}
# J48
# pred     0     1
#    0 16923  3283
#    1  1141  1280
# [1] 0.8044814
# [1] "TARGET ~ MEAN_USAGE"
```

