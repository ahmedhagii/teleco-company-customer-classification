---
title: "vodafone-classification"
author: "ahmed-akram"
date: "May 23, 2016"
output: html_document
---

```{r}
library(aod)
```

```{r cross validation function}
cross_validate <- function(data, model, class, folds, ntree = NULL, print=FALSE, type=NULL, frm=NULL) {
    # folds
    k = folds
    
    # give each row an id from 1:k representing which fold it's in
    data$id <- sample(1:k, nrow(data), replace = TRUE)
    list <- 1:k
    
    data[[class]] <- factor(data[[class]])
    
    progress.bar <- create_progress_bar("text")
    progress.bar$init(k)
    
    accuracies = c()
    precisions = c()
    recalls = c()
    f_scores = c()
    
    for (i in 1:k){
        # get all rows with id != i to be in training set and those with id == i will be testing set
        trainingset <- data %>% subset(id %in% list[-i])
        testset <- data %>% subset(id %in% c(i))
        # building the formula
        if(is.null(frm)) {
        	frm <- paste(class, ".", sep=" ~ ")
        }
        print(frm)
        # building the fitting model
        if(is.null(ntree)) {
            fit <- frm %>% formula %>% model(data=data)
        }else if(!is.null(type)) {
            fit <- frm %>% formula %>% model(data=data, type=type)
        }else{
            fit <- frm %>% formula %>% model(data=data, ntree = ntree)
        }
        
        # get the index of the class in the list of feature names
        index <- which(data %>% names == class)
        
        # predict on the test set without the desired class column
        pred <- predict(fit, testset[,-index])
        
        confusion_matrix <- table(pred, testset[[class]])
        #rownames(confusion_matrix) <- c("Predicted No", "Predicted Yes")
        #colnames(confusion_matrix) <- c("Actual No", "Actual Yes")
        
        if(print) {
            print(confusion_matrix)
        }
        
        TN <- confusion_matrix[1,1]
        TP <- confusion_matrix[2,2]
        FP <- confusion_matrix[2,1]
        FN <- confusion_matrix[1,2]
        
        accuracy <- (TP + TN) / (testset %>% nrow)
        precision <- (TP) / (FP + TP)
        recall <- (TP) / (TP + FN)
        f_score <- 2 * (recall * precision) / (recall + precision)
        
        accuracies <- accuracies %>% append(accuracy)
        precisions <- precisions %>% append(precision)
        recalls <- recalls %>% append(recall)
        f_scores <- f_scores %>% append(f_score)
        
        progress.bar$step()
    }
    
    return (as.data.frame(list("Accuracy" = accuracies, 
                               "Precision" = precisions,
                               "Recall" = recalls,
                               "F_Score" = f_scores)))
}
```

```{r divide into train and test for local validation}
divide_data <- function() {
nr <- NROW(model_train)
ind <- sample(nr, 0.7 * nr, replace = FALSE)
train <<- model_train[ind,]
test <<- model_train[-ind,]
}
divide_data()
```

```{r calculate function}
calculate <- function(fit) {
	pred <- predict(fit, newdata = test[, -12])
	confusion_matrix <- table(pred, test$TARGET)
	print(confusion_matrix)
	
	TN <- confusion_matrix[1,1]
	TP <- confusion_matrix[2,2]
	FP <- confusion_matrix[2,1]
	FN <- confusion_matrix[1,2]
	# accuracy <- (TP + TN) / (test %>% nrow)
	accuracy <- (TP + TN) / (TN + TP + FP + FN)
	print(accuracy)
	return(TP)
}
```


```{r naive bayes}
fit <- naiveBayes(TARGET ~ TOTAL_USAGE + AVG_PER_SESSION + WEIGHTED_AVG + DIFF_BETWEEN_6th_AND_MEAN + BIGGER_THAN + GENDER, data = train)
calculate(fit)
```

```{r bagging}
fit <-  bagging(as.factor(TARGET) ~ TOTAL_USAGE + AVG_PER_SESSION + SUM_EXCEEDING + WEIGHTED_AVG + RATE_PLAN + AGE, data = train, type='class')
calculate(fit)
```

```{r decision tree}
fit <- J48(as.factor(TARGET) ~ TOTAL_USAGE + AVG_PER_SESSION + SUM_EXCEEDING + WEIGHTED_AVG, data = train)
calculate(fit)
```

```{r random forest}
fit <- randomForest(as.factor(TARGET) ~ TOTAL_USAGE + AVG_PER_SESSION + SUM_EXCEEDING + WEIGHTED_AVG, data = train, ntree=100)
calculate(fit)
```


```{r submission 10}
fit <- naiveBayes(as.factor(TARGET) ~ TOTAL_USAGE + SUM_EXCEEDING + MEAN_USAGE + WEIGHTED_AVG + BIGGER_THAN, data=model_train)
# pred <- predict(fit, newdata = model_test)
submit(10, fit, model_test)
```

```{r submission 11}
fit <- J48(as.factor(TARGET) ~ AVG_PER_SESSION + DIFF_BETWEEN_6th_AND_MEAN + BIGGER_THAN, data=model_train)
# pred <- predict(fit, newdata = model_test)
submit(11, fit, model_test)
```

# Submission 12:
```{r}
fit <- naiveBayes(as.factor(TARGET) ~ TOTAL_USAGE + SUM_EXCEEDING + MEAN_USAGE + WEIGHTED_AVG + BIGGER_THAN, data=model_train)

submit <- function(number, fit, data) {

	pred <- predict(fit, newdata = data)
	print(pred %>% unique)
	
	data$PREDICTED_TARGET = pred
	data$PREDICTED_TARGET <- data %>% apply(1, function(row) {
		if(as.numeric(row[['DIFF_BETWEEN_6th_AND_MEAN']]) > 135) {
			return(1)
		}else {
			return(row[['PREDICTED_TARGET']])
		}
	})
	data$PREDICTED_TARGET <- data %>% apply(1, function(row) {
		if(as.numeric(row[['MONTH5_USAGE']]) > as.numeric(row[['MEAN_USAGE']]) + 500) {
			return(1)
		}else {
			return(row[['PREDICTED_TARGET']])
		}
	})
	
	data <- data %>% dplyr::select(CONTRACT_KEY, PREDICTED_TARGET)
	
	file <- paste("submissions/submission-", number, ".csv", sep="")
	write.csv(data, file, row.names = FALSE)
}

submit(12, fit, model_test)
```

# Submission 13:
Let's try some forecasting methods to try and project the usage of the 6th month, then we can simple check if it will pass the average of the past 5 months or not, or we can use the forecasted data in enhancing the performance of the models. I already tried the weighted average forecasting and added the 'WEIGHTED_AVG' feature. Now let's try the (drifting method), where the change in the forecasted data is affected by the average change in previous data.
```{r}
model_train$DRIFT_FORECAST <- model_train %>% apply(1, function(x) {
	cc <- as.numeric(
		c(
			x[['MONTH1_USAGE']], 
			x[['MONTH2_USAGE']], 
			x[['MONTH3_USAGE']], 
			x[['MONTH4_USAGE']], 
			x[['MONTH5_USAGE']]
		))
	frc <- rwf(cc, h=5, drift=TRUE)
	if(mean(frc$mean[1:3]) > 0) {
		return(mean(frc$mean[1:3]))
	}else {
		return(cc[5])	
	}
})
```


```{r}
calender_ref <- read.csv("data/calendar_ref.csv")
model_test <- merge(x = model_test, y = contract_ref, by = 'CONTRACT_KEY')
model_train <- merge(x = model_train, y = contract_ref, by = 'CONTRACT_KEY')


yes <- model_train %>% subset(TARGET == 1)
no <- model_train %>% subset(TARGET == 0)
svm_dataset <- yes %>% sample_n(size = 4000)
svm_dataset <- yes %>% sample_n(size = 4000)
svm_dataset %>% nrow
svm_dataset <- svm_dataset %>% rbind(no %>% sample_n(size= 16000))

svm_dataset <- svm_dataset[sample(nrow(svm_dataset)), ]
svm_dataset <- svm_dataset %>% dplyr::select(-diff_one, -diff_one2, -diff_two, -diff_two2, -diff_three, -diff_three2)

svm_dataset.with_nas <- svm_dataset
svm_dataset <- svm_dataset %>% dplyr::select(-GENDER, -ROAMING_COUNTER)

```



```{r}
fit <- randomForest(as.factor(TARGET) ~ TOTAL_USAGE + AVG_PER_SESSION + SUM_EXCEEDING + DRIFT_FORECAST, data = train, ntree=100)

	pred <- predict(fit, newdata = test[, -12])
	confusion_matrix <- table(pred, test$TARGET)
	confusion_matrix
	
	TN <- confusion_matrix[1,1]
	TP <- confusion_matrix[2,2]
	FP <- confusion_matrix[2,1]
	FN <- confusion_matrix[1,2]
	# accuracy <- (TP + TN) / (test %>% nrow)
	accuracy <- (TP + TN) / (TN + TP + FP + FN)
	accuracy
```


```{r, cache=TRUE, fig.width=11, fig.height=8}
model_train %>% 
	subset(MEAN_USAGE < 10000) %>% 
	subset(DRIFT_FORECAST < 30000) %>% 
	ggplot(aes(x=MEAN_USAGE, y=DRIFT_FORECAST)) + 
	geom_point(aes(color=factor(TARGET))) +
	scale_color_manual("Target\n",labels = c("0", "1"), values = c("#EFADA9", "#69B5C7")) +
	theme(axis.title.y = element_text(size=12,angle=0,hjust=0.5,vjust=1,lineheight=40)) +
	theme(axis.text.x = element_text(size=10,angle=45)) +
	theme(axis.title.x = element_text(size=12)) +
	theme(plot.title = element_text(size=12)) +
	scale_x_continuous(breaks = floor(seq(min(model_train$MEAN_USAGE), max(model_train$MEAN_USAGE), by = 500))) +
  	scale_y_continuous(breaks = floor(seq(min(model_train$DRIFT_FORECAST), max(model_train$DRIFT_FORECAST), by = 1000))) +
	labs(title = "Forecasted 6th month vs. Mean of 5 months (Figure 5)", x="5 Months Mean Usage", y="6th Month usage")
```

```{r diff between drift and avg bs. avg, cache=TRUE, fig.width=11, fig.height=8}
model_train %>% 
	subset(MEAN_USAGE < 10000) %>% 
	subset(DRIFT_FORECAST < 30000) %>% 
	mutate(new_diff = DRIFT_FORECAST - MEAN_USAGE) %>%
	subset(new_diff < 1000) %>%
	subset(new_diff > -1000) %>%
	ggplot(aes(x=MEAN_USAGE, y=new_diff)) + 
	geom_point(aes(color=factor(TARGET))) +
	scale_color_manual("Target\n",labels = c("0", "1"), values = c("#EFADA9", "#69B5C7")) +
	theme(axis.title.y = element_text(size=12,angle=0,hjust=0.5,vjust=1,lineheight=40)) +
	theme(axis.text.x = element_text(size=10,angle=45)) +
	theme(axis.title.x = element_text(size=12)) +
	theme(plot.title = element_text(size=12)) +
	scale_x_continuous(breaks = floor(seq(min(model_train$MEAN_USAGE), max(model_train$MEAN_USAGE), by = 500))) +
  	scale_y_continuous(breaks = floor(seq(from = -1000, to=1000, by = 100))) +
	labs(title = "Forecasted 6th month vs. Mean of 5 months (Figure 5)", x="5 Months Mean Usage", y="6th Month usage")
```

```{r density of diff between drift and avg, cache=TRUE, fig.width=12, fig.height=7}
model_train %>% 
	mutate(new_diff = DRIFT_FORECAST - MEAN_USAGE) %>%
	subset(new_diff < 1000) %>%
	subset(new_diff > -1000) %>%
	ggplot(aes(new_diff, fill=factor(TARGET))) +
	scale_fill_manual("Target\n",labels = c("0", "1"), values = c("#EFADA9", "#69B5C7")) +
    geom_density(alpha=I(0.7)) +
	theme(axis.title.y = element_text(size=12,angle=0,hjust=0.5,vjust=1,lineheight=40)) +
	theme(axis.title.x = element_text(size=12)) +
	theme(axis.text.x = element_text(size=10,angle=45)) + 
	theme(plot.title = element_text(size=13,angle=0)) + 
	labs(title = "Density for (6th_Month - Five_Months_Avg) (Figure 6)", x="Difference between forecasted 6th month and average", y="Density") + 
	scale_x_continuous(breaks = ceiling(seq(min(model_train$DIFF_BETWEEN_6th_AND_MEAN), max(model_train$DIFF_BETWEEN_6th_AND_MEAN), by = 25)))
```




# Submission 14:
```{r submission 12 - general linera regression}
logit <- glm(TARGET ~ TOTAL_USAGE + TOTAL_SESSIONS + AVG_PER_SESSION + SUM_EXCEEDING + MEAN_USAGE, data = train)
logit %>% summary
```
As we can see, the model doesn't use the MEAN_USAGE feature, so let's drop it.
```{r}
logit <- glm(TARGET ~ TOTAL_USAGE + TOTAL_SESSIONS + AVG_PER_SESSION + SUM_EXCEEDING + DIFF_BETWEEN_6th_AND_MEAN, data=train, family=binomial)
logit %>% summary

exp(coef(logit))
```
From the exponentiated coefficients above, we can say that increasing one unit in most of the features used in the model, will increase thethe odds of the TARGET being 1 by ~ 1

```{r}
logit <- lm(TARGET ~ TOTAL_USAGE + TOTAL_SESSIONS + AVG_PER_SESSION + SUM_EXCEEDING + DIFF_BETWEEN_6th_AND_MEAN, data=train)
plot(logit)
```

```{r}
ee <- model_train %>% head(5)
ee %>% apply(1, function(x) {
	cc <- as.numeric(c(x[['MONTH1_USAGE']], x[['MONTH2_USAGE']], x[['MONTH3_USAGE']], x[['MONTH4_USAGE']], x[['MONTH5_USAGE']]))
	print(mean(cc))
	print(cc)
	f <- auto.arima(cc, d=0, xreg=c(1,2,3,4,5))
	print(f)
	print(x[['TARGET']])
	print("")
})
```


```{r try all funcion}
try_all <- function(model) {
# 	features <- c("TOTAL_USAGE", "BIGGER_THAN")
	features <- c("TOTAL_USAGE", "AVG_PER_SESSION", "SUM_EXCEEDING", "MEAN_USAGE", "WEIGHTED_AVG", "DIFF_BETWEEN_6th_AND_MEAN", "BIGGER_THAN")

	substrRight <- function(x, n){
		substr(x, nchar(x)-n+1, nchar(x))
	}
	
	max_score = 0
	best_form = ""
	
	train[["TARGET"]] <- factor(train[["TARGET"]])
	
	rec <- function(index, frm) {
		if(index > length(features)) {
			if(frm == "") {
				return(" .")
			}
			return(frm)
		}
		
		if(frm == "") {
			formula = paste(frm, features[index], sep=" ")
		}else {
			formula = paste(frm, features[index], sep=" + ")
		}
		
		used_formula <- formula
		frm2 <- paste("TARGET", used_formula, sep=" ~")
		print(frm2)
		
		if(model == 1) {
			fit <-  naiveBayes(as.formula(frm2), data = train)	
		}else if(model == 2) {
			fit <-  randomForest(as.formula(frm2), data = train, ntree=50)
		}else if(model == 3) {
			fit <-  bagging(as.formula(frm2), data = train)
		}else if(model == 4) {
			fit <-  J48(as.formula(frm2), data = train)
		}else if(model ==5) {
			fit <-  svm(as.formula(frm2), data = train, type="C-classification")			
		}else {
			fit <- glm(as.formula(frm2), data=train, family = binomial())
			pred <- predict(fit, newdata = test, type = "response")
			test$PREDICTED_TARGET = pred
			test <- test %>% mutate(PREDICTED_TARGET = as.numeric(PREDICTED_TARGET >= 0.5))
			confusion_matrix<- table(test$PREDICTED_TARGET, test$TARGET)
			print(confusion_matrix)
			TN <- confusion_matrix[1,1]
			TP <- confusion_matrix[2,2]
			FP <- confusion_matrix[2,1]
			FN <- confusion_matrix[1,2]
			# accuracy <- (TP + TN) / (test %>% nrow)
			accuracy <- (TP + TN) / (TN + TP + FP + FN)
			print(accuracy)
			res <- TP
		}
		if(model != 6) {
			res <- calculate(fit)	
		}
		
		if(as.numeric(res) > max_score) {
			best_form <<- frm2
			max_score <<- res
		}
		print("====================")
		rec(index + 1, formula)
		rec(index + 1, frm)
	}

	
	rec(1, "")
	print(paste("Best score achieved ", max_score, "with formula: ", best_form))
}
```

```{r try every possible formula attributes with the following algorithms}
sink("output/naivebayes.out", append=FALSE)
try_all(1)
sink()
sink()
print("Done [naiveBayes]")

sink("output/randomForest.out", append=FALSE)
try_all(2)
sink()
print("Done [randomForest]")

sink("output/bagging.out", append=FALSE)
try_all(3)
sink()
print("Done [bagging]")
# 
sink("output/J48.out", append=FALSE)
try_all(4)
sink()
print("Done [J48]")

sink("output/svm.out", append=FALSE)
try_all(5)
sink()
print("Done [svm]")

```




```{r}
# divide_data()
pred <- predict(fit, newdata = test)
test$PREDICTED_TARGET = pred
test$PREDICTED_TARGET <- test %>% apply(1, function(row) {
		if(as.numeric(row[['DIFF_BETWEEN_6th_AND_MEAN']]) > 135) {
			return(1)
		}else {
			return(row[['PREDICTED_TARGET']])
		}
	})
confusion_matrix<- table(test$PREDICTED_TARGET, test$TARGET)
confusion_matrix
TN <- confusion_matrix[1,1]
TP <- confusion_matrix[2,2]
FP <- confusion_matrix[2,1]
FN <- confusion_matrix[1,2]
accuracy <- (TP + TN) / (TN + TP + FP + FN)
accuracy
accuracy_one <-  TP / (FN + TP)
accuracy_zero <- TN / (TN + FP)
paste("accurace_one ", accuracy_one)
paste("accurace_zero ", accuracy_zero)
```



```{r submit}
submit <- function(number, fit, data) {

	pred <- predict(fit, newdata = data)
	print(pred %>% unique)
	
	data$PREDICTED_TARGET = pred
	data$PREDICTED_TARGET <- data %>% apply(1, function(row) {
		if(as.numeric(row[['DIFF_BETWEEN_6th_AND_MEAN']]) > 135) {
			return(1)
		}else {
			return(row[['PREDICTED_TARGET']])
		}
	})
	data$PREDICTED_TARGET <- data %>% apply(1, function(row) {
		if(as.numeric(row[['MONTH5_USAGE']]) > as.numeric(row[['MEAN_USAGE']]) + 500) {
			return(1)
		}else {
			return(row[['PREDICTED_TARGET']])
		}
	})
	
	data <- data %>% dplyr::select(CONTRACT_KEY, PREDICTED_TARGET)
	
	file <- paste("submissions/submission-", number, ".csv", sep="")
	write.csv(data, file, row.names = FALSE)
}
```
